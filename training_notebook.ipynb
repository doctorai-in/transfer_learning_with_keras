{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs == 2\n",
      "platform True\n",
      "gs://kubeflow-test-288607-kubeflowpipelines-default/transfer-learning-keras-training/data/train\n",
      "gs://kubeflow-test-288607-kubeflowpipelines-default/transfer-learning-keras-training/data/test\n",
      "tf.Tensor(\n",
      "[b'gs://kubeflow-test-288607-kubeflowpipelines-default/transfer-learning-keras-training/data/train/train-00000-of-00002'\n",
      " b'gs://kubeflow-test-288607-kubeflowpipelines-default/transfer-learning-keras-training/data/train/train-00001-of-00002'], shape=(2,), dtype=string)\n",
      "WARNING:tensorflow:From /home/omen/lab/GCP/Transfer_Learning/transfer_learning_with_keras/utils/dataset.py:104: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/omen/lab/GCP/Transfer_Learning/transfer_learning_with_keras/utils/dataset.py:104: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/omen/.local/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:201: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/omen/.local/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:201: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'gs://kubeflow-test-288607-kubeflowpipelines-default/transfer-learning-keras-training/data/test/test-00000-of-00002'\n",
      " b'gs://kubeflow-test-288607-kubeflowpipelines-default/transfer-learning-keras-training/data/test/test-00001-of-00002'], shape=(2,), dtype=string)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Finished creating ./models/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "xception (Functional)        (None, 7, 7, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               12845184  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 33,706,793\n",
      "Trainable params: 12,845,313\n",
      "Non-trainable params: 20,861,480\n",
      "_________________________________________________________________\n",
      "current directory is : /home/omen/lab/GCP/Transfer_Learning/transfer_learning_with_keras\n",
      "Epoch 1/2\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5996 - accuracy: 0.5000WARNING:tensorflow:From /home/omen/.local/lib/python3.6/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/omen/.local/lib/python3.6/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - ETA: 0s - loss: 31.5271 - accuracy: 0.8500\n",
      "Epoch 00001: val_loss improved from inf to 0.00000, saving model to ./models/2/checkpoints/cat_dog_clf2_weights.01-31.53.hdf5\n",
      "10/10 [==============================] - 6s 570ms/step - loss: 31.5271 - accuracy: 0.8500 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 2/2\n",
      "10/10 [==============================] - ETA: 0s - loss: 8.3726 - accuracy: 0.9375\n",
      "Epoch 00002: val_loss did not improve from 0.00000\n",
      "10/10 [==============================] - 5s 500ms/step - loss: 8.3726 - accuracy: 0.9375 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:save model\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "import argparse\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "import string\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.metrics import binary_accuracy\n",
    "from tensorflow.keras.models import load_model\n",
    "import shutil\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Activation, add, Dense, Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import yaml\n",
    "import tensorflow.keras as keras\n",
    "import sys\n",
    "from load_tf_record import TFRecordLoader\n",
    "#sys.path.append('../')\n",
    "from utils.dataset import get_dataset\n",
    "########### Logger setup ##############\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "######### Load config ######################################\n",
    "stream = open('config.yaml', 'r')\n",
    "config_arg = yaml.safe_load(stream)\n",
    "######## set argument ######################################\n",
    "epochs = int(config_arg['training']['epoch'])\n",
    "print('epochs == {}'.format(epochs))\n",
    "batch_size = int(config_arg['training']['train_batch'])\n",
    "val_batch_size = int(config_arg['training']['val_batch'])\n",
    "model_version = str(config_arg['training']['version'])\n",
    "loss = config_arg['training']['loss'] # binary_crossentropy or categorical_crossentropy\n",
    "class_mode = config_arg['data_generator']['class_mode'] # binary or categorical\n",
    "img_target_size = config_arg['image']['size']\n",
    "\n",
    "\n",
    "MODEL_ARCHITECTURE = config_arg['type'] + model_version + \".json\"\n",
    "CHECK_POINT = config_arg['type'] + model_version + '_weights.{epoch:02d}-{loss:.2f}.hdf5'\n",
    "MODEL_FILE = config_arg['type'] + model_version + '_model.h5'\n",
    "WEIGHT_FILE = config_arg['type'] + model_version + '_weights_.h5'\n",
    "HISTORY_FILE = 'history_' + config_arg['type'] + model_version + '.csv'\n",
    "LR_FILE='lr_' + config_arg['type'] + model_version + '.csv'\n",
    "platform = str(config_arg['platform'])\n",
    "print(\"platform\", platform==\"gcp\")\n",
    "if platform == 'gcp':\n",
    "    TRAIN_DIR = str(config_arg['data']['gcp']['train'])\n",
    "    EVAL_DIR = str(config_arg['data']['gcp']['test'])\n",
    "    destination = config_arg['save_model']['local']['path_prefix']\n",
    "else:\n",
    "    TRAIN_DIR = config_arg['data']['local']['train']\n",
    "    EVAL_DIR = config_arg['data']['local']['test']\n",
    "    destination = config_arg['save_model']['local']['path_prefix']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########### Training data generator ########\n",
    "#FILENAMES_TRAIN = tf.io.gfile.glob(\"/home/omen/lab/GCP/Transfer_Learning/tfrecord/train*\")\n",
    "#FILENAMES_EVAL = tf.io.gfile.glob(\"/home/omen/lab/GCP/Transfer_Learning/tfrecord/test*\")\n",
    "\n",
    "#data_loader = TFRecordLoader(batch_size, img_target_size)\n",
    "print(TRAIN_DIR)\n",
    "print(EVAL_DIR)\n",
    "train_generator = get_dataset(TRAIN_DIR, 'train', batch_size=batch_size)\n",
    "eval_generator =  get_dataset(EVAL_DIR, 'test', batch_size=1)\n",
    "debug=False\n",
    "if debug:\n",
    "    image_batch, label_batch = next(iter(train_generator))\n",
    "    data_loader.show_batch(image_batch.numpy(), label_batch.numpy())\n",
    "    print(\"train_generator: \", train_generator)\n",
    "############ Define Model ##############\n",
    "nb_epochs = epochs\n",
    "\n",
    "\n",
    "# Create base model\n",
    "basemodel = keras.applications.Xception(\n",
    "    weights='imagenet',\n",
    "    input_shape=(img_target_size, img_target_size, 3),\n",
    "    include_top=False)\n",
    "\n",
    "# Freeze base model\n",
    "basemodel.trainable = False\n",
    "\n",
    "# Create new model on top.\n",
    "inputs = keras.Input(shape=(img_target_size, img_target_size, 3))\n",
    "x = basemodel(inputs, training=False)\n",
    "\n",
    "# Full connection\n",
    "flatten = Flatten()(x) \n",
    "fc1 = Dense(units = 128, activation = 'relu')(flatten)\n",
    "fc2_out = Dense(units = 1, activation = 'sigmoid')(fc1)\n",
    "\n",
    "model = tf.keras.Model(inputs, fc2_out)\n",
    "\n",
    "#for layer in basemodel.layers:\n",
    "    #layer.trainable = False\n",
    "\n",
    "\n",
    "opt = Adam(lr=5e-4, decay=0.1)\n",
    "initial_learning_rate = 0.01\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=20, decay_rate=0.96, staircase=True\n",
    ")\n",
    "model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "\n",
    "logger.debug(\"Model summary...\")\n",
    "model.count_params()\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "############# Support infra #########\n",
    "checkpoint_path = None\n",
    "log_path = None\n",
    "\n",
    "dirpath = os.getcwd()\n",
    "print(\"current directory is : \" + dirpath)\n",
    "destination = destination + model_version\n",
    "if os.path.isdir(destination):\n",
    "    shutil.rmtree(destination, ignore_errors = True)\n",
    "    logger.info(\"Removed old {}\".format(destination))\n",
    "os.makedirs(destination)\n",
    "checkpoint_path = destination + \"/checkpoints\"\n",
    "os.mkdir(checkpoint_path)\n",
    "log_path = destination + \"/logs\"\n",
    "os.mkdir(log_path)\n",
    "logger.info(\"Finished creating {}\".format(destination))\n",
    "\n",
    "\n",
    "# Write model architecture\n",
    "with open(os.path.join(destination , MODEL_ARCHITECTURE), \"w\") as f:\n",
    "        f.write(model.to_json())\n",
    "\n",
    "run_id = \"cat_dog-\" + str(batch_size) + \"-\" + '' \\\n",
    ".join(random\n",
    "      .SystemRandom()\n",
    "      .choice(string.ascii_uppercase) for _ in range(10)\n",
    ")\n",
    "\n",
    "\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "def schedule(epoch, lr):\n",
    "    if epoch%25 == 0:\n",
    "        return lr * 0.5\n",
    "    return lr\n",
    "#lr_scheduler = LearningRateScheduler(schedule, verbose=0)\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        os.path.join(checkpoint_path, CHECK_POINT),\n",
    "        monitor=\"val_loss\",\n",
    "        verbose=1,\n",
    "        save_best_only=True,\n",
    "        mode=\"auto\"\n",
    "        ),\n",
    "    TensorBoard(log_dir= os.path.join(log_path,run_id) ),\n",
    "    #lr_scheduler,\n",
    "    ]\n",
    "\n",
    "########### Run the model #############\n",
    "hist = model.fit(\n",
    "train_generator,\n",
    "callbacks = callbacks,\n",
    "batch_size=16,\n",
    "steps_per_epoch = 10,# there are around 9776 images, % by batch size of 16\n",
    "epochs=nb_epochs,\n",
    "validation_data=eval_generator,\n",
    "shuffle=True,\n",
    "validation_steps=2,\n",
    "#verbose=2,\n",
    ")\n",
    "\n",
    "## Print lr ###\n",
    "#print(lr_scheduler.history)\n",
    "\n",
    "######## Save Model ###############\n",
    "logger.info(\"save model\")\n",
    "model.save(os.path.join(destination, MODEL_FILE))\n",
    "model.save_weights(os.path.join(destination, WEIGHT_FILE), overwrite=True)\n",
    "pd.DataFrame(hist.history).to_csv(os.path.join(destination,HISTORY_FILE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-5c1a2b0d6637c42c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-5c1a2b0d6637c42c\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6009;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./models/2/logs/cat_dog-8-FFXEERWOXY/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
